{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, DataCollatorForSeq2Seq\n",
    "from transformers.models.t5.modeling_t5 import T5LayerFF\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from huggingface_hub import HfApi\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbbe0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "trainset_range = list(range(0, 15000))\n",
    "testset_range = list(range(18000, 22000))\n",
    "base_t5_path = \"t5-small\"\n",
    "medmcqa_dataset_path = \"openlifescienceai/medmcqa\"\n",
    "checkpoint_file = \"T5-Finetuned-15k-20epoch.pth\"\n",
    "test_dataset_file_name = \"MEDMCQA-test-dataset-4k.json\"\n",
    "repo_id = \"MMK79/Medical-RAG\"\n",
    "# push_model_to_huggingface = False\n",
    "# push_dataset_to_huggingface = False\n",
    "push_model_to_huggingface = True\n",
    "push_dataset_to_huggingface = True\n",
    "\n",
    "batch_size = 8\n",
    "lr = 1e-4\n",
    "num_epochs = 20\n",
    "bottleneck_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d59a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(base_t5_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(base_t5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1632f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_idx2str = {\n",
    "    0: \"A\",\n",
    "    1: \"B\",\n",
    "    2: \"C\",\n",
    "    3: \"D\",\n",
    "}\n",
    "dataset = load_dataset(medmcqa_dataset_path)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"].select(trainset_range)\n",
    "test_dataset = dataset[\"train\"].select(testset_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac9518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_none(example):\n",
    "    return (\n",
    "        (example[\"exp\"] is not None)\n",
    "        and (len(example[\"exp\"]) > 20)\n",
    "        and (example[\"question\"] is not None)\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.filter(filter_none)\n",
    "test_dataset = test_dataset.filter(filter_none)\n",
    "test_dataset_raw = test_dataset.filter(filter_none)\n",
    "dataset[\"validation\"] = dataset[\"validation\"].filter(filter_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23acc7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example_training(row):\n",
    "    input_text = f\"Question: {row['question']}\\n\\nOptions:\\nA: {row['opa']}\\nB: {row['opb']}\\nC: {row['opc']}\\nD: {row['opd']}\\n\\nExplanation: {row['exp']}\\n\\nAnswer:\"\n",
    "    target_text = f\"Answer: {opt_idx2str[row['cop']]}\"\n",
    "    return {\"input_text\": input_text, \"target_text\": target_text}\n",
    "\n",
    "\n",
    "def format_example_validation(row):\n",
    "    input_text = f\"Question: {row['question']}\\n\\nOptions:\\nA: {row['opa']}\\nB: {row['opb']}\\nC: {row['opc']}\\nD: {row['opd']}\\n\\nExplanation: {row['exp']}\\n\\nAnswer:\"\n",
    "    target_text = f\"Answer: {opt_idx2str[row['cop']]}\"\n",
    "    return {\"input_text\": input_text, \"target_text\": target_text}\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    format_example_training, remove_columns=train_dataset.column_names\n",
    ")\n",
    "test_dataset = test_dataset.map(\n",
    "    format_example_training, remove_columns=test_dataset.column_names\n",
    ")\n",
    "dataset[\"validation\"] = dataset[\"validation\"].map(\n",
    "    format_example_validation, remove_columns=dataset[\"validation\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa4c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_function(row):\n",
    "    input_info = tokenizer(row[\"input_text\"], truncation=True, max_length=1024)\n",
    "    output_info = tokenizer(row[\"target_text\"])\n",
    "    return {**input_info, \"labels\": output_info.input_ids}\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(map_function, batched=True)\n",
    "train_dataset.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.map(map_function, batched=True)\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "dataset[\"validation\"] = dataset[\"validation\"].map(map_function, batched=True)\n",
    "dataset[\"validation\"].set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_fn = DataCollatorForSeq2Seq(tokenizer, return_tensors=\"pt\", padding=\"longest\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, collate_fn=col_fn, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=col_fn)\n",
    "val_loader = DataLoader(dataset[\"validation\"], batch_size=batch_size, collate_fn=col_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81dac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loader, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    batch_losses = []\n",
    "\n",
    "    for row in tqdm(loader):\n",
    "        row = row.to(model.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(**row)\n",
    "        loss = out.loss\n",
    "        batch_loss_value = loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_losses.append(batch_loss_value)\n",
    "    loss_value = np.mean(batch_losses)\n",
    "    return {\"train_loss\": loss_value}\n",
    "\n",
    "\n",
    "def predict(model, row):\n",
    "    return model.generate(\n",
    "        input_ids=row.input_ids, attention_mask=row.attention_mask, max_length=5\n",
    "    )\n",
    "\n",
    "\n",
    "def tokenizer_ids_to_label(all_input_ids):\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "\n",
    "    filtered_input_ids = [\n",
    "        [token_id for token_id in seq if 0 <= token_id < vocab_size]\n",
    "        for seq in all_input_ids\n",
    "    ]\n",
    "\n",
    "    return tokenizer.batch_decode(filtered_input_ids, skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def valid_loop(model, loader, compute_metric):\n",
    "    model.eval()\n",
    "\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for row in tqdm(loader):\n",
    "            row = row.to(model.device)\n",
    "            pred = predict(model, row)\n",
    "\n",
    "            all_true += row.labels.detach().cpu().tolist()\n",
    "            all_pred += pred.detach().cpu().tolist()\n",
    "\n",
    "    all_true = tokenizer_ids_to_label(all_true)\n",
    "    all_pred = tokenizer_ids_to_label(all_pred)\n",
    "\n",
    "    return {\"valid_acc\": compute_metric(y_true=all_true, y_pred=all_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf03c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapter layer\n",
    "class AdapterLayer(nn.Module):\n",
    "    def __init__(self, emb_dim: int, bottleneck_size: int):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.sharif_llm_adapter = nn.Sequential(\n",
    "            nn.Linear(emb_dim, bottleneck_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(bottleneck_size, emb_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        adapter_output = self.sharif_llm_adapter(x)\n",
    "        output = x + adapter_output\n",
    "        return output\n",
    "\n",
    "\n",
    "class FeedForwardAdapterWrapper(nn.Module):\n",
    "    def __init__(self, original_module: T5LayerFF, bottleneck_size: int):\n",
    "\n",
    "        super().__init__()\n",
    "        assert isinstance(original_module, T5LayerFF)\n",
    "\n",
    "        self.original_module = original_module\n",
    "        emb_dim = original_module.DenseReluDense.wi.in_features\n",
    "        self.adapter = AdapterLayer(emb_dim, bottleneck_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        output = self.original_module(x)\n",
    "        output = self.adapter(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c94f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add adapter to the model\n",
    "def mutate_model_recursive(model: nn.Module, bottleneck_size: int):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, T5LayerFF):\n",
    "            feed_forward_with_adapter = FeedForwardAdapterWrapper(\n",
    "                module, bottleneck_size\n",
    "            )\n",
    "            setattr(model, name, feed_forward_with_adapter)\n",
    "            print(f\"Replaced {name} with FeedForwardAdapterWrapper layer.\")\n",
    "        else:\n",
    "            mutate_model_recursive(module, bottleneck_size)\n",
    "\n",
    "\n",
    "def mutate_model(model: nn.Module, bottleneck_size: int):\n",
    "    if hasattr(model, \"_mutated\"):\n",
    "        print(\"Model already contains adapter layers! \\n Try reloading the model.\")\n",
    "        return\n",
    "\n",
    "    mutate_model_recursive(model, bottleneck_size)\n",
    "\n",
    "    model._mutated = True\n",
    "\n",
    "\n",
    "mutate_model(model, bottleneck_size=bottleneck_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30815248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze non-adapter parameters\n",
    "def freeze_non_adapter(model, peft_key):\n",
    "    print(\"Non freezed weights:\")\n",
    "    total_params = 0\n",
    "    for param_name, weights in model.named_parameters():\n",
    "        weights.requires_grad = peft_key in param_name\n",
    "        if weights.requires_grad:\n",
    "            print(param_name)\n",
    "            total_params += weights.numel()\n",
    "    print(f\"Total number of parameters should be update: {total_params}\")\n",
    "\n",
    "\n",
    "freeze_non_adapter(model, peft_key=\"sharif_llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "model.to(device)\n",
    "\n",
    "all_results = []\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_results = {\"epoch\": epoch}\n",
    "\n",
    "    epoch_results.update(\n",
    "        train_loop(model=model, loader=train_loader, optimizer=optimizer)\n",
    "    )\n",
    "    epoch_results.update(\n",
    "        valid_loop(model=model, loader=val_loader, compute_metric=accuracy_score)\n",
    "    )\n",
    "    all_results.append(epoch_results)\n",
    "\n",
    "    display.clear_output()\n",
    "    display.display(pd.DataFrame(all_results).set_index(\"epoch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2bea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_idx2str = {\n",
    "    0: \"A\",\n",
    "    1: \"B\",\n",
    "    2: \"C\",\n",
    "    3: \"D\",\n",
    "}\n",
    "opt_str2idx = {s: i for i, s in opt_idx2str.items()}\n",
    "\n",
    "\n",
    "def convert_answer(answer):\n",
    "    prefix_str = \"Answer: \"\n",
    "    if answer.startswith(prefix_str):\n",
    "        try:\n",
    "            option = answer[len(prefix_str) :]\n",
    "            return opt_str2idx[option]\n",
    "        except:\n",
    "            return 100\n",
    "    return 100\n",
    "\n",
    "\n",
    "def show_classification_metrics(trues, preds):\n",
    "    preds = [convert_answer(answer) for answer in preds]\n",
    "    trues = [convert_answer(answer) for answer in trues]\n",
    "\n",
    "    accuracy = accuracy_score(trues, preds)\n",
    "    macro_f1 = f1_score(trues, preds, average=\"macro\")\n",
    "    micro_f1 = f1_score(trues, preds, average=\"micro\")\n",
    "    macro_precision = precision_score(trues, preds, average=\"macro\", zero_division=0)\n",
    "    macro_recall = recall_score(trues, preds, average=\"macro\", zero_division=0)\n",
    "    conf_matrix = confusion_matrix(trues, preds)\n",
    "\n",
    "    print(f\"Accuracy        =  {accuracy * 100:.2f}%\")\n",
    "    print(f\"Macro F1-score  =  {macro_f1 * 100:.2f}%\")\n",
    "    print(f\"Micro F1-score  =  {micro_f1 * 100:.2f}%\")\n",
    "    print(f\"Macro Precision =  {macro_precision * 100:.2f}%\")\n",
    "    print(f\"Macro Recall    =  {macro_recall * 100:.2f}%\")\n",
    "\n",
    "    if (\n",
    "        100 in preds\n",
    "    ):  # Model's answer for some questions is not among the question options\n",
    "        class_names = [\"Option A\", \"Option B\", \"Option C\", \"Option D\", \"None\"]\n",
    "    else:  # Model's answer for every single question is among the provided options\n",
    "        class_names = [\"Option A\", \"Option B\", \"Option C\", \"Option D\"]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(\n",
    "        conf_matrix,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "    )\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.ylabel(\"True labels\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf5fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "all_true = []\n",
    "all_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for row in tqdm(test_loader):\n",
    "        row = row.to(model.device)\n",
    "        pred = predict(model, row)\n",
    "\n",
    "        all_true += row.labels.detach().cpu().tolist()\n",
    "        all_pred += pred.detach().cpu().tolist()\n",
    "\n",
    "all_true = tokenizer_ids_to_label(all_true)\n",
    "all_pred = tokenizer_ids_to_label(all_pred)\n",
    "\n",
    "show_classification_metrics(all_true, all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e370a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_true[:20])\n",
    "print()\n",
    "print(all_pred[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94ba5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "    },\n",
    "    checkpoint_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec54462",
   "metadata": {},
   "outputs": [],
   "source": [
    "if push_model_to_huggingface:\n",
    "    # generate a token from Profile > Setting > Access Tokens with write access\n",
    "    api = HfApi(\n",
    "        token=\"\",\n",
    "    )\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=f\"./{checkpoint_file}\",\n",
    "        path_in_repo=checkpoint_file,\n",
    "        repo_id=repo_id,\n",
    "        repo_type=\"model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3051bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to generate answer based on model\n",
    "def generate_answer(row):\n",
    "    input_text = f\"Question: {row['question']}\\n\\nOptions:\\nA: {row['opa']}\\nB: {row['opb']}\\nC: {row['opc']}\\nD: {row['opd']}\\n\\nExplanation: {row['exp']}\\n\\nAnswer:\"\n",
    "    input_ids = tokenizer(input_text, truncation=True, max_length=1024)\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids.to(device), max_length=5)\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0ee246",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query = {\n",
    "    \"question\": \"Which of the following is most characteristic of diabetic neuropathy?\",\n",
    "    \"opa\": \"it is usually bilateral\",\n",
    "    \"opb\": \"pain is not a feature\",\n",
    "    \"opc\": \"it most commonly affects the brain\",\n",
    "    \"opd\": \"it spares the autonomic system\",\n",
    "    \"cop\": 0,\n",
    "    \"exp\": \"Diabetic neuropathy usually presents as peripheral polyneuropathy, usually bilateral, including symptoms of numbness, paresthesia, severe hyperesthesia, and pain. Impairment of proprioceptive fibers can lead to gait abnormalities and Charcot's joints. Mononeuropathy is less common and is often spontaneously reversible. Common syndromes include wrist or foot drop and third, fourth, or sixth cranial nerve palsies. Autonomic neuropathy may cause gastroesophageal dysfunction, bladder dysfunction, and orthostatic hypotension.\",\n",
    "}\n",
    "\n",
    "model_ans = generate_answer(sample_query)\n",
    "print(f'Model\\'s output =  \"{model_ans}\"')\n",
    "\n",
    "correct_ans = f\"Answer: {opt_idx2str[sample_query['cop']]}\"\n",
    "print(f'Correct output =  \"{correct_ans}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_raw_df = pd.DataFrame(test_dataset_raw.to_dict())\n",
    "test_dataset_raw_df.to_json(test_dataset_file_name)\n",
    "\n",
    "if push_dataset_to_huggingface:\n",
    "    # generate a token from Profile > Setting > Access Tokens with write access\n",
    "    api = HfApi(\n",
    "        token=\"\",\n",
    "    )\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=f\"./{test_dataset_file_name}\",\n",
    "        path_in_repo=test_dataset_file_name,\n",
    "        repo_id=repo_id,\n",
    "        repo_type=\"model\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
